{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yfin\n",
    "yfin.pdr_override()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import skfuzzy as fuzz\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import arch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data from yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>348.399994</td>\n",
       "      <td>348.399994</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>340.600006</td>\n",
       "      <td>314.235657</td>\n",
       "      <td>491114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>338.000000</td>\n",
       "      <td>341.700012</td>\n",
       "      <td>334.350006</td>\n",
       "      <td>338.500000</td>\n",
       "      <td>312.298157</td>\n",
       "      <td>1223210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>338.000000</td>\n",
       "      <td>339.799988</td>\n",
       "      <td>334.549988</td>\n",
       "      <td>335.250000</td>\n",
       "      <td>309.299652</td>\n",
       "      <td>417953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>334.500000</td>\n",
       "      <td>338.799988</td>\n",
       "      <td>334.500000</td>\n",
       "      <td>336.799988</td>\n",
       "      <td>310.729736</td>\n",
       "      <td>348768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-05</td>\n",
       "      <td>338.000000</td>\n",
       "      <td>342.899994</td>\n",
       "      <td>336.049988</td>\n",
       "      <td>337.299988</td>\n",
       "      <td>311.191040</td>\n",
       "      <td>711437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>2023-07-28</td>\n",
       "      <td>1171.449951</td>\n",
       "      <td>1190.400024</td>\n",
       "      <td>1155.699951</td>\n",
       "      <td>1177.800049</td>\n",
       "      <td>1177.800049</td>\n",
       "      <td>4454009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>1181.800049</td>\n",
       "      <td>1184.750000</td>\n",
       "      <td>1165.400024</td>\n",
       "      <td>1175.000000</td>\n",
       "      <td>1175.000000</td>\n",
       "      <td>2221571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>1175.000000</td>\n",
       "      <td>1187.300049</td>\n",
       "      <td>1168.099976</td>\n",
       "      <td>1178.349976</td>\n",
       "      <td>1178.349976</td>\n",
       "      <td>1362536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>2023-08-02</td>\n",
       "      <td>1185.000000</td>\n",
       "      <td>1185.000000</td>\n",
       "      <td>1153.550049</td>\n",
       "      <td>1168.300049</td>\n",
       "      <td>1168.300049</td>\n",
       "      <td>1861901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3234</th>\n",
       "      <td>2023-08-03</td>\n",
       "      <td>1166.050049</td>\n",
       "      <td>1178.949951</td>\n",
       "      <td>1150.000000</td>\n",
       "      <td>1165.849976</td>\n",
       "      <td>1165.849976</td>\n",
       "      <td>2574025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3235 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date         Open         High          Low        Close  \\\n",
       "0    2010-06-29   348.399994   348.399994   340.000000   340.600006   \n",
       "1    2010-06-30   338.000000   341.700012   334.350006   338.500000   \n",
       "2    2010-07-01   338.000000   339.799988   334.549988   335.250000   \n",
       "3    2010-07-02   334.500000   338.799988   334.500000   336.799988   \n",
       "4    2010-07-05   338.000000   342.899994   336.049988   337.299988   \n",
       "...         ...          ...          ...          ...          ...   \n",
       "3230 2023-07-28  1171.449951  1190.400024  1155.699951  1177.800049   \n",
       "3231 2023-07-31  1181.800049  1184.750000  1165.400024  1175.000000   \n",
       "3232 2023-08-01  1175.000000  1187.300049  1168.099976  1178.349976   \n",
       "3233 2023-08-02  1185.000000  1185.000000  1153.550049  1168.300049   \n",
       "3234 2023-08-03  1166.050049  1178.949951  1150.000000  1165.849976   \n",
       "\n",
       "        Adj Close   Volume  \n",
       "0      314.235657   491114  \n",
       "1      312.298157  1223210  \n",
       "2      309.299652   417953  \n",
       "3      310.729736   348768  \n",
       "4      311.191040   711437  \n",
       "...           ...      ...  \n",
       "3230  1177.800049  4454009  \n",
       "3231  1175.000000  2221571  \n",
       "3232  1178.349976  1362536  \n",
       "3233  1168.300049  1861901  \n",
       "3234  1165.849976  2574025  \n",
       "\n",
       "[3235 rows x 7 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data=pdr.get_data_yahoo('CIPLA.NS',start='2010-06-29',end='2023-08-04')\n",
    "main_data=main_data.reset_index()\n",
    "main_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock=main_data[\"Close\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the metrics dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.read_csv(\"metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA-ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = main_data.Date\n",
    "close=main_data.Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3234,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_values = close.pct_change().dropna() # shape 3297 -->3296\n",
    "return_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chakr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\chakr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\chakr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "arma_order = (1, 0, 1)  \n",
    "arma_model = sm.tsa.arima.ARIMA(return_values, order=arma_order)\n",
    "arma_results = arma_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = arma_results.resid\n",
    "\n",
    "Xt_1 = return_values.shift(1)\n",
    "Xt_2 = return_values.shift(2)\n",
    "\n",
    "# Lagged Values of the Residuals\n",
    "et_1 = residual.shift(1)\n",
    "et_2 = residual.shift(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Xt_1</th>\n",
       "      <th>Xt_2</th>\n",
       "      <th>et_1</th>\n",
       "      <th>et_2</th>\n",
       "      <th>Yt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>-0.009601</td>\n",
       "      <td>-0.006166</td>\n",
       "      <td>-0.010340</td>\n",
       "      <td>-0.006677</td>\n",
       "      <td>0.004623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-05</td>\n",
       "      <td>0.004623</td>\n",
       "      <td>-0.009601</td>\n",
       "      <td>0.003766</td>\n",
       "      <td>-0.010340</td>\n",
       "      <td>0.001485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.004623</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.003766</td>\n",
       "      <td>0.004744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-07-07</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>-0.012541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-07-08</td>\n",
       "      <td>-0.012541</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>-0.012907</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.014343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>2023-07-28</td>\n",
       "      <td>0.096350</td>\n",
       "      <td>0.013036</td>\n",
       "      <td>0.096267</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.005421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>0.005421</td>\n",
       "      <td>0.096350</td>\n",
       "      <td>0.008180</td>\n",
       "      <td>0.096267</td>\n",
       "      <td>-0.002377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>-0.002377</td>\n",
       "      <td>0.005421</td>\n",
       "      <td>-0.002703</td>\n",
       "      <td>0.008180</td>\n",
       "      <td>0.002851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>2023-08-02</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>-0.002377</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>-0.002703</td>\n",
       "      <td>-0.008529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3234</th>\n",
       "      <td>2023-08-03</td>\n",
       "      <td>-0.008529</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>-0.008961</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>-0.002097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3232 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date      Xt_1      Xt_2      et_1      et_2        Yt\n",
       "3    2010-07-02 -0.009601 -0.006166 -0.010340 -0.006677  0.004623\n",
       "4    2010-07-05  0.004623 -0.009601  0.003766 -0.010340  0.001485\n",
       "5    2010-07-06  0.001485  0.004623  0.001112  0.003766  0.004744\n",
       "6    2010-07-07  0.004744  0.001485  0.004266  0.001112 -0.012541\n",
       "7    2010-07-08 -0.012541  0.004744 -0.012907  0.004266  0.014343\n",
       "...         ...       ...       ...       ...       ...       ...\n",
       "3230 2023-07-28  0.096350  0.013036  0.096267  0.012696  0.005421\n",
       "3231 2023-07-31  0.005421  0.096350  0.008180  0.096267 -0.002377\n",
       "3232 2023-08-01 -0.002377  0.005421 -0.002703  0.008180  0.002851\n",
       "3233 2023-08-02  0.002851 -0.002377  0.002242 -0.002703 -0.008529\n",
       "3234 2023-08-03 -0.008529  0.002851 -0.008961  0.002242 -0.002097\n",
       "\n",
       "[3232 rows x 6 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({\"Date\": date[1:],\n",
    "                            \"Xt_1\": Xt_1,\n",
    "                            \"Xt_2\": Xt_2,\n",
    "                            \"et_1\": et_1,\n",
    "                            \"et_2\": et_2,\n",
    "                            \"Yt\": return_values\n",
    "                                 })\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"Xt_1\",\"Xt_2\",\"et_1\",\"et_2\"]]\n",
    "y = data['Yt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=32, activation='relu', input_shape=(X.shape[1],)))\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chakr\\AppData\\Local\\Temp\\ipykernel_11360\\161937034.py:4: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y_train, y_test = y[:train_size], y[train_size:]\n",
      "c:\\Users\\chakr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py:1696: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 2s 6ms/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 2/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.5108e-04 - val_loss: 9.6869e-04\n",
      "Epoch 3/50\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3.0729e-04 - val_loss: 7.2336e-04\n",
      "Epoch 4/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.9328e-04 - val_loss: 8.5265e-04\n",
      "Epoch 5/50\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.7624e-04 - val_loss: 6.9544e-04\n",
      "Epoch 6/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.7821e-04 - val_loss: 8.5594e-04\n",
      "Epoch 7/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.1440e-04 - val_loss: 7.8805e-04\n",
      "Epoch 8/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.8823e-04 - val_loss: 6.4560e-04\n",
      "Epoch 9/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.9592e-04 - val_loss: 7.2568e-04\n",
      "Epoch 10/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.8793e-04 - val_loss: 6.6384e-04\n",
      "Epoch 11/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.7861e-04 - val_loss: 6.4486e-04\n",
      "Epoch 12/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.8175e-04 - val_loss: 6.7302e-04\n",
      "Epoch 13/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.8711e-04 - val_loss: 7.5891e-04\n",
      "Epoch 14/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.9370e-04 - val_loss: 6.3448e-04\n",
      "Epoch 15/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6406e-04 - val_loss: 6.8384e-04\n",
      "Epoch 16/50\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.7910e-04 - val_loss: 6.5726e-04\n",
      "Epoch 17/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.8277e-04 - val_loss: 7.0804e-04\n",
      "Epoch 18/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.7024e-04 - val_loss: 6.3845e-04\n",
      "Epoch 19/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.7694e-04 - val_loss: 6.7865e-04\n",
      "Epoch 20/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6993e-04 - val_loss: 6.3396e-04\n",
      "Epoch 21/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.3080e-04 - val_loss: 0.0010\n",
      "Epoch 22/50\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3.0371e-04 - val_loss: 8.5268e-04\n",
      "Epoch 23/50\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.6579e-04 - val_loss: 6.5646e-04\n",
      "Epoch 24/50\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.6462e-04 - val_loss: 7.8146e-04\n",
      "Epoch 25/50\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.6727e-04 - val_loss: 6.9524e-04\n",
      "Epoch 26/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6597e-04 - val_loss: 9.7055e-04\n",
      "Epoch 27/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.9049e-04 - val_loss: 6.6177e-04\n",
      "Epoch 28/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.7329e-04 - val_loss: 7.2013e-04\n",
      "Epoch 29/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.7949e-04 - val_loss: 9.6103e-04\n",
      "Epoch 30/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.8896e-04 - val_loss: 8.3049e-04\n",
      "Epoch 31/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.8232e-04 - val_loss: 6.3720e-04\n",
      "Epoch 32/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6752e-04 - val_loss: 6.7468e-04\n",
      "Epoch 33/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6980e-04 - val_loss: 6.5313e-04\n",
      "Epoch 34/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6209e-04 - val_loss: 6.3284e-04\n",
      "Epoch 35/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6748e-04 - val_loss: 6.7504e-04\n",
      "Epoch 36/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.8691e-04 - val_loss: 9.8774e-04\n",
      "Epoch 37/50\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.7441e-04 - val_loss: 6.8682e-04\n",
      "Epoch 38/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.7022e-04 - val_loss: 7.1910e-04\n",
      "Epoch 39/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5810e-04 - val_loss: 6.1232e-04\n",
      "Epoch 40/50\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.6311e-04 - val_loss: 7.0499e-04\n",
      "Epoch 41/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4895e-04 - val_loss: 7.5807e-04\n",
      "Epoch 42/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5315e-04 - val_loss: 6.9622e-04\n",
      "Epoch 43/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5188e-04 - val_loss: 8.2923e-04\n",
      "Epoch 44/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5308e-04 - val_loss: 6.8181e-04\n",
      "Epoch 45/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6584e-04 - val_loss: 7.0318e-04\n",
      "Epoch 46/50\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.7322e-04 - val_loss: 7.8786e-04\n",
      "Epoch 47/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6342e-04 - val_loss: 8.0118e-04\n",
      "Epoch 48/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.7053e-04 - val_loss: 6.8817e-04\n",
      "Epoch 49/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5933e-04 - val_loss: 8.7066e-04\n",
      "Epoch 50/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6218e-04 - val_loss: 7.3506e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_size = int(0.8 * len(X))  \n",
    "\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step - loss: 2.7280e-04\n",
      "Test Loss: 0.00027279520872980356\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 26 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002AA2F50C700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "Predicted Value: 0.0124743795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chakr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "new_data = np.array([[-0.014049,0.034767,-0.015659,0.033157]])\n",
    "new_data = scaler.transform(new_data)  \n",
    "prediction = model.predict(new_data)\n",
    "print(\"Predicted Value:\", prediction[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 0.01651651303069767\n",
      "Mean Absolute Error (MAE): 0.012318199202481365\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_ann_metrics = pd.DataFrame([{'models':'ARIMA-ANN', 'RootMeanSquaredError':rmse, 'MeanAbsoluteError':mae}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>RootMeanSquaredError</th>\n",
       "      <th>MeanAbsoluteError</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression(Multiple)</td>\n",
       "      <td>3.632006</td>\n",
       "      <td>2.701710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>0.043155</td>\n",
       "      <td>0.030573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sarima</td>\n",
       "      <td>0.043220</td>\n",
       "      <td>0.030645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR(1)</td>\n",
       "      <td>0.043154</td>\n",
       "      <td>0.030574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GARCH(1,1)</td>\n",
       "      <td>0.043162</td>\n",
       "      <td>0.001863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arma-Garch(1,1)(1,1)</td>\n",
       "      <td>0.043180</td>\n",
       "      <td>0.030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ARIMA-ANN</td>\n",
       "      <td>0.016517</td>\n",
       "      <td>0.012318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        models  RootMeanSquaredError  MeanAbsoluteError\n",
       "0  Linear Regression(Multiple)              3.632006           2.701710\n",
       "1                    ARMA(2,2)              0.043155           0.030573\n",
       "2                       Sarima              0.043220           0.030645\n",
       "3                        AR(1)              0.043154           0.030574\n",
       "4                   GARCH(1,1)              0.043162           0.001863\n",
       "5         Arma-Garch(1,1)(1,1)              0.043180           0.030600\n",
       "6                    ARIMA-ANN              0.016517           0.012318"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.concat([metrics,arima_ann_metrics ], ignore_index= True)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARMA-GARCH-ANN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      -0.006166\n",
       "2      -0.009601\n",
       "3       0.004623\n",
       "4       0.001485\n",
       "5       0.004744\n",
       "          ...   \n",
       "3230    0.005421\n",
       "3231   -0.002377\n",
       "3232    0.002851\n",
       "3233   -0.008529\n",
       "3234   -0.002097\n",
       "Name: Close, Length: 3234, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock = stock.pct_change().dropna()\n",
    "stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chakr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\chakr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\chakr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "arma_order = (1, 0, 1)  \n",
    "arma_model = sm.tsa.arima.ARIMA(stock, order=arma_order)\n",
    "arma_results = arma_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      6,   Neg. LLF: 5421249627.134298\n",
      "Iteration:      2,   Func. Count:     18,   Neg. LLF: 978804747.5146753\n",
      "Iteration:      3,   Func. Count:     30,   Neg. LLF: 3371745930.579838\n",
      "Iteration:      4,   Func. Count:     43,   Neg. LLF: 2230558690.0203137\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -8822.648923743134\n",
      "            Iterations: 5\n",
      "            Function evaluations: 53\n",
      "            Gradient evaluations: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chakr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\arch\\univariate\\base.py:310: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
      "estimating the model parameters. The scale of y is 0.0002661. Parameter\n",
      "estimation work better when this value is between 1 and 1000. The recommended\n",
      "rescaling is 100 * y.\n",
      "\n",
      "This warning can be disabled by either rescaling y before initializing the\n",
      "model or by setting rescale=False.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "garch_order = (1, 1)  # Replace with the appropriate GARCH order (p, q)\n",
    "garch_model = arch.arch_model(arma_results.resid, vol='Garch', p=garch_order[0], q=garch_order[1])\n",
    "garch_results = garch_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = garch_results.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Xt_1      Xt_2      et_1      et_2        Yt\n",
      "3    -0.009601 -0.006166 -0.010405 -0.006741  0.004623\n",
      "4     0.004623 -0.009601  0.003702 -0.010405  0.001485\n",
      "5     0.001485  0.004623  0.001047  0.003702  0.004744\n",
      "6     0.004744  0.001485  0.004202  0.001047 -0.012541\n",
      "7    -0.012541  0.004744 -0.012972  0.004202  0.014343\n",
      "...        ...       ...       ...       ...       ...\n",
      "3230  0.096350  0.013036  0.096202  0.012632  0.005421\n",
      "3231  0.005421  0.096350  0.008116  0.096202 -0.002377\n",
      "3232 -0.002377  0.005421 -0.002768  0.008116  0.002851\n",
      "3233  0.002851 -0.002377  0.002178 -0.002768 -0.008529\n",
      "3234 -0.008529  0.002851 -0.009025  0.002178 -0.002097\n",
      "\n",
      "[3232 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataframe for using ARMA_GARCH_ANN Model\n",
    "\n",
    "# Lagged Values of the actual return price \n",
    "Xt_1 = stock.shift(1)\n",
    "Xt_2 = stock.shift(2)\n",
    "\n",
    "\n",
    "# Lagged Values of the Residuals\n",
    "et_1 = residuals.shift(1)\n",
    "et_2 = residuals.shift(2)\n",
    "\n",
    "# Creating the dataframe\n",
    "arma_garch_ann_df = pd.DataFrame({\n",
    "    'Xt_1': Xt_1,\n",
    "    'Xt_2': Xt_2,\n",
    "    'et_1': et_1,\n",
    "    'et_2': et_2,\n",
    "    'Yt': stock\n",
    "})\n",
    "\n",
    "# Droping the null values \n",
    "arma_garch_ann_df.dropna(inplace=True)\n",
    "\n",
    "#Printing the data\n",
    "print(arma_garch_ann_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chakr\\AppData\\Local\\Temp\\ipykernel_11360\\1117127597.py:19: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y_train, y_test = y[:train_size], y[train_size:]\n",
      "c:\\Users\\chakr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py:1696: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "73/73 [==============================] - 2s 5ms/step - loss: 0.0111 - val_loss: 0.0015\n",
      "Epoch 2/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.3973e-04 - val_loss: 9.8091e-04\n",
      "Epoch 3/50\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3.4550e-04 - val_loss: 8.4444e-04\n",
      "Epoch 4/50\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3.1660e-04 - val_loss: 8.3710e-04\n",
      "Epoch 5/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.9825e-04 - val_loss: 7.4165e-04\n",
      "Epoch 6/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.7386e-04 - val_loss: 7.9901e-04\n",
      "Epoch 7/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6346e-04 - val_loss: 7.3278e-04\n",
      "Epoch 8/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5913e-04 - val_loss: 6.7560e-04\n",
      "Epoch 9/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5757e-04 - val_loss: 7.0595e-04\n",
      "Epoch 10/50\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2.5473e-04 - val_loss: 7.1112e-04\n",
      "Epoch 11/50\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2.5245e-04 - val_loss: 7.3694e-04\n",
      "Epoch 12/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5193e-04 - val_loss: 6.7513e-04\n",
      "Epoch 13/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5247e-04 - val_loss: 6.8896e-04\n",
      "Epoch 14/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5944e-04 - val_loss: 7.1245e-04\n",
      "Epoch 15/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5105e-04 - val_loss: 6.8037e-04\n",
      "Epoch 16/50\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.5069e-04 - val_loss: 6.5337e-04\n",
      "Epoch 17/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5456e-04 - val_loss: 6.6141e-04\n",
      "Epoch 18/50\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.5094e-04 - val_loss: 6.6335e-04\n",
      "Epoch 19/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5259e-04 - val_loss: 6.5775e-04\n",
      "Epoch 20/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4806e-04 - val_loss: 6.7296e-04\n",
      "Epoch 21/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4718e-04 - val_loss: 6.4777e-04\n",
      "Epoch 22/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4648e-04 - val_loss: 6.6777e-04\n",
      "Epoch 23/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5133e-04 - val_loss: 6.4792e-04\n",
      "Epoch 24/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4869e-04 - val_loss: 6.5858e-04\n",
      "Epoch 25/50\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2.5349e-04 - val_loss: 6.5128e-04\n",
      "Epoch 26/50\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2.4601e-04 - val_loss: 6.4535e-04\n",
      "Epoch 27/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5059e-04 - val_loss: 6.3650e-04\n",
      "Epoch 28/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4956e-04 - val_loss: 6.4801e-04\n",
      "Epoch 29/50\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2.5636e-04 - val_loss: 6.3301e-04\n",
      "Epoch 30/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4752e-04 - val_loss: 6.6033e-04\n",
      "Epoch 31/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4683e-04 - val_loss: 6.4148e-04\n",
      "Epoch 32/50\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2.5021e-04 - val_loss: 7.3805e-04\n",
      "Epoch 33/50\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2.5043e-04 - val_loss: 6.3035e-04\n",
      "Epoch 34/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5286e-04 - val_loss: 6.2999e-04\n",
      "Epoch 35/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4497e-04 - val_loss: 6.5054e-04\n",
      "Epoch 36/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4538e-04 - val_loss: 6.3493e-04\n",
      "Epoch 37/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4927e-04 - val_loss: 6.3967e-04\n",
      "Epoch 38/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4523e-04 - val_loss: 6.7160e-04\n",
      "Epoch 39/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4621e-04 - val_loss: 6.2226e-04\n",
      "Epoch 40/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4819e-04 - val_loss: 6.3750e-04\n",
      "Epoch 41/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5071e-04 - val_loss: 6.3781e-04\n",
      "Epoch 42/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5081e-04 - val_loss: 6.3550e-04\n",
      "Epoch 43/50\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2.4514e-04 - val_loss: 6.1670e-04\n",
      "Epoch 44/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5030e-04 - val_loss: 6.4854e-04\n",
      "Epoch 45/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5064e-04 - val_loss: 6.6238e-04\n",
      "Epoch 46/50\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2.4260e-04 - val_loss: 6.3998e-04\n",
      "Epoch 47/50\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2.4177e-04 - val_loss: 6.2457e-04\n",
      "Epoch 48/50\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2.4665e-04 - val_loss: 6.5086e-04\n",
      "Epoch 49/50\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2.4031e-04 - val_loss: 6.5902e-04\n",
      "Epoch 50/50\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2.4203e-04 - val_loss: 6.4457e-04\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 2.2138e-04\n",
      "Test Loss: 0.00022138492204248905\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Predicted Value: -0.0055391258\n",
      "21/21 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chakr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = arma_garch_ann_df[['Xt_1', 'Xt_2', 'et_1', 'et_2']]\n",
    "y = arma_garch_ann_df['Yt']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=32, activation='relu', input_shape=(X.shape[1],)))\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(X))  \n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "\n",
    "\n",
    "new_data = np.array([[-0.014049,0.034767,-0.015659,0.033157]])\n",
    "new_data = scaler.transform(new_data)  \n",
    "prediction = model.predict(new_data)\n",
    "print(\"Predicted Value:\", prediction[0][0])\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 0.01487900938893959\n",
      "Mean Absolute Error (MAE): 0.010744818910452232\n"
     ]
    }
   ],
   "source": [
    "rmse1 = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse1)\n",
    "\n",
    "# Calculate MAE\n",
    "mae1 = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_garch_ann_metrics = pd.DataFrame([{'models':'ARIMA-GARCH-ANN', 'RootMeanSquaredError':rmse1, 'MeanAbsoluteError':mae1}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>RootMeanSquaredError</th>\n",
       "      <th>MeanAbsoluteError</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression(Multiple)</td>\n",
       "      <td>3.632006</td>\n",
       "      <td>2.701710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>0.043155</td>\n",
       "      <td>0.030573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sarima</td>\n",
       "      <td>0.043220</td>\n",
       "      <td>0.030645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR(1)</td>\n",
       "      <td>0.043154</td>\n",
       "      <td>0.030574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GARCH(1,1)</td>\n",
       "      <td>0.043162</td>\n",
       "      <td>0.001863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arma-Garch(1,1)(1,1)</td>\n",
       "      <td>0.043180</td>\n",
       "      <td>0.030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ARIMA-ANN</td>\n",
       "      <td>0.016517</td>\n",
       "      <td>0.012318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ARIMA-GARCH-ANN</td>\n",
       "      <td>0.014879</td>\n",
       "      <td>0.010745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        models  RootMeanSquaredError  MeanAbsoluteError\n",
       "0  Linear Regression(Multiple)              3.632006           2.701710\n",
       "1                    ARMA(2,2)              0.043155           0.030573\n",
       "2                       Sarima              0.043220           0.030645\n",
       "3                        AR(1)              0.043154           0.030574\n",
       "4                   GARCH(1,1)              0.043162           0.001863\n",
       "5         Arma-Garch(1,1)(1,1)              0.043180           0.030600\n",
       "6                    ARIMA-ANN              0.016517           0.012318\n",
       "7              ARIMA-GARCH-ANN              0.014879           0.010745"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.concat([metrics,arima_garch_ann_metrics], ignore_index= True)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUZZY CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock1 = main_data[\"Close\"]\n",
    "stock1 = stock1.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 3\n",
    "\n",
    "# Fuzzy C-Means clustering\n",
    "cntr, u, _, _, _, _, _ = fuzz.cluster.cmeans(stock1.T, num_clusters, 2, error=0.005, maxiter=1000)\n",
    "\n",
    "# Identify the cluster with the highest membership for each data point\n",
    "cluster_membership = np.argmax(u, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data['Cluster'] = cluster_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_num in range(num_clusters):\n",
    "    # Filter data points belonging to the current cluster\n",
    "    cluster_data = main_data[main_data['Cluster'] == cluster_num]\n",
    "    x_train = cluster_data['Close'].values.reshape(-1, 1)\n",
    "    y_train = cluster_data['Close'].shift(-1).fillna(0).values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(16, activation='relu', input_shape=(1,)),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(x_train, y_train, epochs=50, batch_size=16, verbose=0)\n",
    "    \n",
    "    # Example: Predict next day's stock price for the last data point in the cluster\n",
    "    last_price = cluster_data['Close'].iloc[-1]\n",
    "    predicted_price = model.predict(np.array([[last_price]]))\n",
    "    print(f\"Cluster {cluster_num}: Predicted Next Day's Price: {predicted_price[0][0]}\")\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(num_clusters):\n",
    "    plt.scatter(main_data[main_data['Cluster'] == i]['Date'], main_data[main_data['Cluster'] == i]['Close'], label=f'Cluster {i}')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Normalized Stock Price')\n",
    "plt.title('Fuzzy C-Means Clustering of Tesla Stock Prices')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
